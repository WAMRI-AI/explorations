{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from returns.result import Result, Success, Failure\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data. use the smallest training set to start\n",
    "casp11 = \"~/Downloads/casp11/training_30\"\n",
    "#read each line\n",
    "with open(casp11, 'r') as casp:\n",
    "    l = casp.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the formnat of primary, secondary, and tertiary, read in the data\n",
    "primary = []\n",
    "evolutionary = []\n",
    "terti = []\n",
    "ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_read(blob):\n",
    "    try:\n",
    "        return [[float(x) for x in line.split('\\t') if x!=\"\"] for line in blob]\n",
    "    except ValueError as vle:\n",
    "        return Failure(vle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now process the data\n",
    "#experiment with the first 1000 proteins\n",
    "for x, line in enumerate(l):\n",
    "    if len(ids) == 1000:\n",
    "        break\n",
    "    if line == \"[ID]\":\n",
    "        ids.append(l[x+1])\n",
    "    elif line == \"[PRIMARY]\":\n",
    "        primary.append(l[x+1]) \n",
    "    elif line == \"[EVOLUTIONARY]\": #indexes based on explorations of the data format\n",
    "        evolutionary.append(line_read(l[x+1:x+22]))\n",
    "    elif line == \"[TERTIARY]\":\n",
    "        terti.append(line_read(l[x+1:x+4]))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000, 999, 999, 999]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in [ids, primary, evolutionary, terti]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 257, 257: 21, 771: 3})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data attributes\n",
    "#comprehensive check for length of each list in all read-in primary, evolutionary, and tertiary data\n",
    "#clearly there are some 3D arrays there in our data\n",
    "\n",
    "print(Counter([len(x) for x in [primary, evolutionary, terti]]))\n",
    "print(Counter([len(y) for x in [primary, evolutionary, terti] for y in x]))\n",
    "print(Counter([len(y) for x in [primary, evolutionary, terti] for y in x[998]]))\n",
    "print(Counter([len(y) for x in terti for y in x]))\n",
    "print(Counter([len(y) for x in [primary, evolutionary, terti] for y in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with the data, build the coordinates\n",
    "#seqs - primary\n",
    "#pssms - evolutionary (TODO: i know we are getting pssm matrices out of the 2ndary data, but not completely certin how. So i will do the tertiary data first.)\n",
    "#coords - tertiary - we basically have a list of coordinates in this dataset, and we need to find some kind of angles\n",
    "\n",
    "def build_crdnt(crdnt_array, remainder): \n",
    "#remainder can be: 0,1,2\n",
    "    crdnt_list = []\n",
    "    array_len = len(crdnt_array[1])\n",
    "    for i in range(array_len):\n",
    "        if i%3 == remainder:\n",
    "            crdnt_list.append([crdnt_array[j][i] for j in range(3)])\n",
    "    return np.array(crdnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the coordinates\n",
    "crdnt1 = [build_crdnt(crdnt,0) for crdnt in terti] \n",
    "crdnt2 = [build_crdnt(crdnt,1) for crdnt in terti]\n",
    "crdnt3 = [build_crdnt(crdnt,2) for crdnt in terti]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[999, 372, 3]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#common sense check to make sure things work\n",
    "[len(crdnt3 ), len(crdnt3 [1]), len(crdnt3[1][1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#form the coordinates, construct angles, the usual way\n",
    "#c for coordinate. a for angle\n",
    "\n",
    "def build_angle(c1,c2,c3,c4):\n",
    "    a1=c2-c1\n",
    "    a2=c3-c2\n",
    "    a3=c4-c3\n",
    "    \n",
    "    v1=np.cross(a1,a2)\n",
    "    v2=np.cross(a2, a3)\n",
    "    \n",
    "    v1= v1 / (v1 ** 2).sum(-1)**(0.5)\n",
    "    v2= v2 / (v2 ** 2).sum(-1)**(0.5)\n",
    "    \n",
    "    pm=np.sign((a3*v1).sum(-1))\n",
    "    denom= ((v1**2).sum(-1) * (v2**2).sum(-1))**0.5\n",
    "    numerator=(v1*v2).sum(-1)\n",
    "    angle=np.arccos(numerator/ denom)\n",
    "    \n",
    "    if pm!=0:\n",
    "        angle=angle*pm\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n",
      "/home/hj/.local/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "#get the phis and the psis\n",
    "#phi starts and psi ends with 0\n",
    "\n",
    "thephis = []\n",
    "thepsis=[]\n",
    "\n",
    "clen = len(terti)\n",
    "\n",
    "for i in range(clen):\n",
    "    phi=[0.0]\n",
    "    psi=[]\n",
    "    len2=len(crdnt2[i])\n",
    "    \n",
    "    #TODO: for the 1st and last coordinates, there seem to be problems computing phi and psi, respectively. \n",
    "    for j in range(1,len2):\n",
    "        phi_angle = build_angle(crdnt3[i][j-1], crdnt1[i][j], crdnt2[i][j], crdnt3[i][j]) \n",
    "        phi.append(phi_angle)\n",
    "        if j < len2 - 1:\n",
    "            psi_angle = build_angle(crdnt1[i][j], crdnt2[i][j], crdnt3[i][j], crdnt2[i][j+1]) \n",
    "            psi.append(psi_angle)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    psi.append(0.0)\n",
    "    thephis.append(phi)\n",
    "    thepsis.append(psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 999)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print([len(thepsis), len(thephis)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# references: https://en.wikipedia.org/wiki/Amino_acid, section \"Table of standard amino acid abbreviations and properties\"\n",
    "# references: https://en.wikipedia.org/wiki/Proteinogenic_amino_acid, section \"General chemical properties“\n",
    "#[chr(x) for x in range(ord('A'), ord('Z') + 1)]\n",
    "all_aa = ['A','C','D','E','F','G','H','I','K','L','M','N','O','P','Q','R','S','T','U','V','W','Y']\n",
    "#TODO: my hunch is that we need certain proproties - physical and chemical - of the amino acids, but I'm not sure what those properties are\n",
    "#aa = amino acids\n",
    "#aa_props1 = {}\n",
    "#aa_props2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: I'm not totally certain. It seems like there are position and padding parameters involved. this is my current effort\n",
    "#references: https://github.com/aqlaboratory/proteinnet/blob/master/docs/proteinnet_records.md\n",
    "#https://en.wikipedia.org/wiki/Position_weight_matrix\n",
    "\n",
    "def process_pssm(pssm, position, padding):\n",
    "    result=[]\n",
    "    for x, line in enumerate(pssm):\n",
    "        start_index = position - padding\n",
    "        end_index = position + padding\n",
    "        result.append(line[start_index:end_index])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO： I think this is right based on what I researched. Need to further make sure\n",
    "\n",
    "clen=len(primary)\n",
    "pssm_in=[]\n",
    "#TODO: padding length undecided\n",
    "padding_len = 20\n",
    "\n",
    "pssm_input = []\n",
    "pssm_output = []\n",
    "\n",
    "mycount = 0 # Counter to ensure everythings fine\n",
    "\n",
    "for i in range(clen): \n",
    "    if len(primary[i])>padding_len*2:\n",
    "        mycount += len(seqs[i])-padding_len*2\n",
    "        for j in range(padding_len,len(seqs[i])-padding_len):\n",
    "            pssm_input.append(process_pssm(pssms[i], j))\n",
    "            pssm_output.append([thephis[i][j], thepsis[i][j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: 1. finish PSSM. \n",
    "#2. further check on if \"secondary structure\" spoken in the documentation is present in this dataset (I checked multiple times, and want to make sure)\n",
    "#3. finish data processing and onto MLing! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
